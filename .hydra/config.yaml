model:
  _target_: src.model.LCNN
  in_channels: 1
  num_classes: 2
  dropout: 0.5
writer:
  _target_: src.logger.WandBWriter
  project_name: pytorch_template
  entity: null
  run_name: testing
  mode: disabled
  loss_names:
  - loss
  log_checkpoints: false
  id_length: 8
metrics:
  device: auto
  train:
  - _target_: src.metrics.ExampleMetric
    name: TRAIN_Accuracy
    device: ${metrics.device}
    metric:
      _target_: torchmetrics.classification.MulticlassAccuracy
      num_classes: 2
  inference:
  - _target_: src.metrics.ExampleMetric
    name: Accuracy
    device: ${metrics.device}
    metric:
      _target_: torchmetrics.classification.BinaryAccuracy
      threshold: 0.5
  - _target_: src.metrics.ExampleMetric
    name: F1
    device: ${metrics.device}
    metric:
      _target_: torchmetrics.classification.BinaryF1Score
  - _target_: src.metrics.ExampleMetric
    name: AUROC
    device: ${metrics.device}
    metric:
      _target_: torchmetrics.classification.BinaryAUROC
  - _target_: src.metrics.ExampleMetric
    name: EER
    device: ${metrics.device}
    metric:
      _target_: torchmetrics.classification.BinaryAUROC
datasets:
  train:
    _target_: src.datasets.example.ExampleDataset
    root: data/ASVspoof2019/LA
    split: train
    sample_rate: 16000
    n_fft: 512
    win_length: 400
    hop_length: 160
    limit: null
    shuffle_index: true
    instance_transforms: ${transforms.instance_transforms.train}
  val:
    _target_: src.datasets.example.ExampleDataset
    root: data/ASVspoof2019/LA
    split: dev
    sample_rate: 16000
    n_fft: 512
    win_length: 400
    hop_length: 160
    limit: null
    shuffle_index: false
    instance_transforms: ${transforms.instance_transforms.inference}
  test:
    _target_: src.datasets.example.ExampleDataset
    root: data/ASVspoof2019/LA
    split: eval
    sample_rate: 16000
    n_fft: 512
    win_length: 400
    hop_length: 160
    limit: null
    shuffle_index: false
    instance_transforms: ${transforms.instance_transforms.inference}
dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 64
  num_workers: 4
  pin_memory: true
  collate_fn:
    _target_: src.datasets.collate.collate_fn
    _partial_: true
  prefetch_factor: 2
  persistent_workers: true
transforms:
  batch_transforms:
    train:
      data_object:
        _target_: torch.nn.Sequential
        _args_:
        - _target_: src.transforms.Normalize1D
          mean: 0.0
          std: 1.0
        - _target_: torchaudio.transforms.FrequencyMasking
          freq_mask_param: 8
        - _target_: torchaudio.transforms.TimeMasking
          time_mask_param: 15
    inference:
      data_object:
        _target_: torch.nn.Sequential
        _args_:
        - _target_: src.transforms.Normalize1D
          mean: 0.0
          std: 1.0
  instance_transforms:
    train:
      data_object:
        _target_: torchvision.transforms.v2.Compose
        transforms:
        - _target_: src.transforms.RandomScale1D
    inference: null
optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0001
  weight_decay: 0.0001
lr_scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  gamma: 0.98
  step_size: ${trainer.epoch_len}
loss_function:
  _target_: src.loss.ExampleLoss
  weight:
  - 1.0
  - 5.0
  label_smoothing: 0.1
trainer:
  monitor: max val_AUROC
  log_step: 50
  n_epochs: 100
  epoch_len: 500
  device_tensors:
  - data_object
  - labels
  resume_from: model_best.pth
  device: auto
  override: false
  save_period: 3
  early_stop: ${trainer.n_epochs}
  save_dir: Q://deeplearn
  seed: 1
out_csv: grading/students_solutions/artur.csv
