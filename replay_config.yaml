model:
  _target_: src.model.LCNN
  in_channels: 1
  num_classes: 2
  dropout: 0.5
writer:
  _target_: src.logger.WandBWriter
  project_name: pytorch_template
  entity: null
  run_name: lcnn_mel_cmvn600
  mode: disabled
  loss_names:
  - loss
  log_checkpoints: false
  id_length: 8
metrics:
  device: auto
  train:
  - _target_: src.metrics.example.ExampleMetric
    name: TRAIN_Accuracy
    device: ${metrics.device}
    metric: null
  inference:
  - _target_: src.metrics.example.ExampleMetric
    name: Accuracy
    device: ${metrics.device}
    metric: null
  - _target_: src.metrics.example.ExampleMetric
    name: F1
    device: ${metrics.device}
    metric: null
  - _target_: src.metrics.example.ExampleMetric
    name: AUROC
    device: ${metrics.device}
    metric: null
  - _target_: src.metrics.example.ExampleMetric
    name: EER
    device: ${metrics.device}
    metric: null
datasets:
  train:
    _target_: src.datasets.example.ExampleDataset
    root: data/ASVspoof2019/LA
    split: train
    sample_rate: 16000
    n_fft: 512
    win_length: 400
    hop_length: 160
    limit: null
    shuffle_index: true
    instance_transforms: ${transforms.instance_transforms.train}
    max_frames: 600
  val:
    _target_: src.datasets.example.ExampleDataset
    root: data/ASVspoof2019/LA
    split: dev
    sample_rate: 16000
    n_fft: 512
    win_length: 400
    hop_length: 160
    limit: null
    shuffle_index: false
    instance_transforms: ${transforms.instance_transforms.inference}
    max_frames: 600
  test:
    _target_: src.datasets.example.ExampleDataset
    root: data/ASVspoof2019/LA
    split: eval
    sample_rate: 16000
    n_fft: 512
    win_length: 400
    hop_length: 160
    limit: null
    shuffle_index: false
    instance_transforms: ${transforms.instance_transforms.inference}
    max_frames: 600
dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 48
  num_workers: 6
  pin_memory: false
  collate_fn:
    _target_: src.datasets.collate.collate_fn
    _partial_: true
  drop_last: false
transforms:
  batch_transforms:
    train:
      data_object:
        _target_: torch.nn.Sequential
        _args_:
        - _target_: src.transforms.normalize.Standardize2D
        - _target_: torchaudio.transforms.FrequencyMasking
          freq_mask_param: 8
        - _target_: torchaudio.transforms.TimeMasking
          time_mask_param: 15
    inference:
      data_object:
        _target_: torch.nn.Sequential
        _args_:
        - _target_: src.transforms.normalize.Standardize2D
        - _target_: src.transforms.normalize.CenterCropPadTime
          max_frames: ${datasets.test.max_frames}
  instance_transforms:
    train:
      data_object:
        _target_: torchvision.transforms.v2.Compose
        transforms:
        - _target_: src.transforms.RandomScale1D
    inference: null
optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0001
  weight_decay: 0.0001
lr_scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  gamma: 0.98
  step_size: ${trainer.epoch_len}
loss_function:
  _target_: src.loss.ExampleLoss
  weight:
  - 1.0
  - 5.0
  label_smoothing: 0.1
trainer:
  monitor: min val_EER
  log_step: 50
  n_epochs: 15
  epoch_len: 600
  device_tensors:
  - data_object
  - labels
  resume_from: C:\Users\artur\Desktop\minicourse\deeplearning_mini-course\saved_fix2\lcnn_mel_cmvn600\model_best.pth
  device: auto
  override: false
  save_period: 3
  early_stop: ${trainer.n_epochs}
  save_dir: saved_fix2
  seed: 1
score_type: p_bona
apply_tform: true
out_csv: grading/students_solutions/artur.csv
